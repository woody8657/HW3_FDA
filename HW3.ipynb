{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn import linear_model, metrics, model_selection\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>rof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02 00:00:00</td>\n",
       "      <td>902.99</td>\n",
       "      <td>931.80</td>\n",
       "      <td>934.73</td>\n",
       "      <td>899.35</td>\n",
       "      <td>4048270080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>929.17</td>\n",
       "      <td>927.45</td>\n",
       "      <td>936.63</td>\n",
       "      <td>919.53</td>\n",
       "      <td>5413910016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-06 00:00:00</td>\n",
       "      <td>931.17</td>\n",
       "      <td>934.70</td>\n",
       "      <td>943.85</td>\n",
       "      <td>927.28</td>\n",
       "      <td>5392620032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-07 00:00:00</td>\n",
       "      <td>927.45</td>\n",
       "      <td>906.65</td>\n",
       "      <td>927.45</td>\n",
       "      <td>902.37</td>\n",
       "      <td>4704940032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-08 00:00:00</td>\n",
       "      <td>905.73</td>\n",
       "      <td>909.73</td>\n",
       "      <td>910.00</td>\n",
       "      <td>896.81</td>\n",
       "      <td>4991549952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date  Open Price  Close Price  High Price  Low Price  \\\n",
       "0  2009-01-02 00:00:00      902.99       931.80      934.73     899.35   \n",
       "1  2009-01-05 00:00:00      929.17       927.45      936.63     919.53   \n",
       "2  2009-01-06 00:00:00      931.17       934.70      943.85     927.28   \n",
       "3  2009-01-07 00:00:00      927.45       906.65      927.45     902.37   \n",
       "4  2009-01-08 00:00:00      905.73       909.73      910.00     896.81   \n",
       "\n",
       "       Volume  rof  \n",
       "0  4048270080    0  \n",
       "1  5413910016    0  \n",
       "2  5392620032    1  \n",
       "3  4704940032    0  \n",
       "4  4991549952    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('download.csv')\n",
    "dateFormatter = \"%d-%b-%y\"\n",
    "for i in range(data.shape[0]):\n",
    "    data.iloc[i,0] = datetime.strptime(data.iloc[i,0], dateFormatter)\n",
    "#新增漲跌的label\n",
    "data['rof'] = 0\n",
    "for i in range(data.shape[0]):\n",
    "    if data.iloc[i,2]>data.iloc[i-1,2]:\n",
    "        data.loc[i,'rof'] = 1\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data['Date']<=pd.datetime(2018,1,1)]\n",
    "test = data[data['Date']>=pd.datetime(2018,1,1)]\n",
    "x_train = train.loc[:, train.columns != 'rof']\n",
    "y_train = train['rof']\n",
    "x_test = test.loc[:, test.columns != 'rof']\n",
    "y_test = test['rof']\n",
    "x_train = x_train.drop('Date',axis = 1)\n",
    "x_test = x_test.drop('Date',axis = 1)\n",
    "\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "X_train_std = scaler.transform(x_train)\n",
    "X_test_std = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8253968253968254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression().fit(X_train_std, y_train['rof'].values)\n",
    "test_preds = lr.predict(X_test_std)\n",
    "test_acc = metrics.accuracy_score(y_test['rof'].values, test_preds)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty = 10.00, Accuracy = 82.94 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "  \n",
    "penalty = 10\n",
    "#penalty = np.linspace(start=0.05, stop=10, num=200)\n",
    "\n",
    "#for c in penalty:\n",
    "svm = SVC(C=penalty, kernel=\"linear\", probability=True)\n",
    "svm.fit(X_train_std, y_train['rof'].values)\n",
    "acc_rate = accuracy_score(y_test['rof'].values, svm.predict(X_test_std)) * 100\n",
    "print(\"Penalty = %.2f, Accuracy = %.2f %%\" % (penalty, acc_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import model_selection, preprocessing\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = 10  # how many neurons in the hidden layer\n",
    "activation = 'relu'  # activation function for hidden layer\n",
    "l2 = 0.001           # regularization - how much we penalize large parameter values\n",
    "learning_rate = 0.1  # how big our steps are in gradient descent\n",
    "epochs = 20          # how many epochs to train for\n",
    "batch_size = 32      # how many samples to use for each gradient descent update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# add the hidden layer\n",
    "model.add(layers.Dense(input_dim=5,\n",
    "                       units=hidden_units, \n",
    "                       activation=activation))\n",
    "\n",
    "# add the output layer\n",
    "model.add(layers.Dense(input_dim=hidden_units,\n",
    "                       units=1,\n",
    "                       activation='sigmoid'))\n",
    "\n",
    "# define our loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              # Adam is a kind of gradient descent\n",
    "              optimizer=optimizers.Adam(lr=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {\n",
    "    0: 1.,\n",
    "    1: 160 / 302\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, x_train, y_train, x_test, y_test, n=20):\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    with tqdm(total=n) as progress_bar:\n",
    "        for _ in range(n):\n",
    "            model.fit(\n",
    "                x_train, \n",
    "                y_train, \n",
    "                epochs=epochs, \n",
    "                batch_size=batch_size, \n",
    "                class_weight=class_weight, \n",
    "                verbose=False)\n",
    "            train_accs.append(model.evaluate(x_train, y_train, batch_size=32, verbose=False)[1])\n",
    "            test_accs.append(model.evaluate(x_test, y_test, batch_size=32, verbose=False)[1])\n",
    "            progress_bar.update()\n",
    "    print('Avgerage Training Accuracy: %s' % np.average(train_accs))\n",
    "    print('Avgerage Testing Accuracy: %s' % np.average(test_accs))\n",
    "    return train_accs, test_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avgerage Training Accuracy: 0.4540636044508998\n",
      "Avgerage Testing Accuracy: 0.47619047902879263\n"
     ]
    }
   ],
   "source": [
    "_, test_accs = train_and_evaluate(model, X_train_std, y_train['rof'].values, X_test_std, y_test['rof'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
